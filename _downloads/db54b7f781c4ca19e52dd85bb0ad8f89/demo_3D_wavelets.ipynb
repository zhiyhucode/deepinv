{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 3D wavelet denoising\n\nThis example shows how to use a 3D wavelet denoiser for denoising a 3D image. We first apply a standard soft-thresholding\nwavelet denoiser to a 3D brain MRI volume. We then extend the denoiser objective to a redundant dictionary of wavelet\nbases, which does not admit a closed-form solution. We solve the denoising problem using the Dykstra-like algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\n\nfrom deepinv.utils.demo import load_np_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nRESULTS_DIR = BASE_DIR / \"results\"\nDEG_DIR = BASE_DIR / \"degradations\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load base volume image and denoising operators.\nIn this example, we use a T1-weighted brain MRI volume from the BrainWeb dataset (subject id 4) and we add\nGaussian random noise to it. Following the torch convention, the volume is of shape (C, D, H, W), where C is the\nnumber of channels, D is the depth, H is the height, and W is the width. We use a single channel volume in this\nexample.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n\nvolume_data = load_np_url(\n    \"https://huggingface.co/datasets/deepinv/images/resolve/main/brainweb_t1_ICBM_1mm_subject_0.npy?download=true\"\n)\nvolume_data = np.copy(volume_data[::-1, ...])\nvolume_data = torch.from_numpy(volume_data).unsqueeze(0).unsqueeze(0)\nx = volume_data / volume_data.max()\n\nnoise_level_img = 0.1  # Gaussian Noise standard deviation for the degradation\nphysics = dinv.physics.GaussianNoise(sigma=noise_level_img)\n\n# Apply the degradation to the image\ny = physics(x)\n\n# Compute the PSNR\npsnr = dinv.metric.PSNR()(x, y).item()\n\n# Plot the input and the output of the degradation\nlist_images = [x[0, :, 90, :, :], x[0, :, :, 108, :], x[0, :, :, :, 90]]\ndinv.utils.plot(\n    list_images,\n    figsize=(6, 2),\n    suptitle=\"groundtruth brain volume\",\n    cmap=\"viridis\",\n    tight=False,\n    fontsize=12,\n)\nlist_images = [y[0, :, 90, :, :], y[0, :, :, 108, :], y[0, :, :, :, 90]]\ndinv.utils.plot(\n    list_images,\n    figsize=(6, 2),\n    suptitle=\"noisy brain volume, PSNR = {:.2f}dB\".format(psnr),\n    cmap=\"viridis\",\n    tight=False,\n    fontsize=12,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the denoising operator and solve the problem.\nWe use the WaveletPrior class from the models module to solve the problem. This class implements the proximal operator\nof the wavelet prior and can be used as a denoiser. More precisely it solves the following problem\n\n\\begin{align}\\widehat{x} = \\arg\\min_{x} \\frac{1}{2} \\|y - x\\|_2^2 + \\lambda \\|\\Psi x\\|_1 = \\operatorname{prox}_{\\lambda \\|\\Psi \\cdot\\|_1}(y)\\end{align}\n\nwhere $\\Psi$ is the wavelet transform and $\\lambda$ is the thresholding parameter. The solution to\nthis problem is given by the proximal operator of the wavelet prior.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The computational complexity of the wavelet transform in 3D grows cubically with the size of the support. For this\n    reason, we use a wavelets with small support (e.g. db1 to db4) in this example, which limits the performance\n    of the denoiser.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create the wavelet denoiser\nwv = \"db4\"\ndenoiser = dinv.models.wavdict.WaveletDenoiser(\n    wv=wv,\n    wvdim=3,\n    level=3,\n)\n\n# Apply the denoiser to the volume\nths = noise_level_img * 2  # thresholding parameter\nx_hat = denoiser(y, ths)  # denoised volume\npsnr = dinv.metric.PSNR()(x, x_hat).item()  # compute PSNR\n\n# Plot\nlist_images = [x_hat[0, :, 90, :, :], x_hat[0, :, :, 108, :], x_hat[0, :, :, :, 90]]\ndinv.utils.plot(\n    list_images,\n    figsize=(6, 2),\n    suptitle=\"Denoised brain volume. PSNR = {:.2f}dB\".format(psnr),\n    cmap=\"viridis\",\n    tight=False,\n    fontsize=12,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extension to multiple wavelet bases.\nInstead of solving the problem in a single wavelet basis, one can seek for sparsity in a redundant dictionary of\nwavelet bases. Formally,\n\n\\begin{align}\\widehat{x} = \\arg\\min_{x} \\frac{1}{2} \\|y - x\\|_2^2 + \\sum_{\\ell=1}^{L}\\lambda_{\\ell} \\|\\Psi_{\\ell} x\\|_1,\\end{align}\n\nwhere $\\Psi_{\\ell}$ is the wavelet transform in the $\\ell$-th basis and $\\lambda_{\\ell}$ is the regularization\nparameter for the $\\ell$-th basis. As previously, the solution to this problem is given by the proximal operator of\n$\\sum_{\\ell=1}^{L}\\lambda_i \\|\\Psi_{\\ell} x\\|_1$. In this case however, the proximal operator is not available in closed\nform but can be computed numerically.\n\nA convenient algorithm in this situation is the Dykstra-like algorithm proposed in\n[[Combettes, 2009]](https://pcombet.math.ncsu.edu/jca2.pdf), writing\n\n\\begin{align}\\begin{equation}\n    \\begin{aligned}\n    &\\text{For}\\;n=0,1,\\ldots \\\\\n    &\\quad x_{n+1} = \\sum_{\\ell=1}^L \\omega_{\\ell} \\operatorname{prox}_{g_\\ell}z_{\\ell,n}, \\\\\n    &\\quad \\text{For}\\;\\ell=1,\\ldots,L \\\\\n    &\\quad \\quad z_{\\ell,n+1} = x_{n+1} + z_{\\ell,n} - \\operatorname{prox}_{g_\\ell}z_{\\ell,n},\n    \\end{aligned}\n    \\end{equation}\\end{align}\n\n\nwhere $\\omega_{\\ell} = 1/L$ for all $\\ell$ and $g_{\\ell} = \\lambda_{\\ell} \\|\\Psi_{\\ell} \\cdot\\|_1$.\nIn turn, the sequence $(x_n)_{n\\in \\mathbb{N}}$ converges to the solution of the original problem.\nWe can implement it as follows. First, let's define the several proximity operators we'll need.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "list_wv = [\"haar\", \"db2\", \"db3\", \"db4\"]\nnon_linearity = \"soft\"\nlist_prox = nn.ModuleList(\n    [\n        dinv.models.wavdict.WaveletDenoiser(\n            level=3, wv=wv, non_linearity=non_linearity, wvdim=3\n        )\n        for wv in list_wv\n    ]\n)\n\n# Initialize the first element\nz_p = y.repeat(len(list_prox), *([1] * (len(y.shape))))\np_p = torch.zeros_like(z_p)\nx_cur = p_p.clone()\n\n# Average proximal step\nx_prev = x.clone()\nfor p in range(len(list_prox)):\n    p_p[p, ...] = list_prox[p](z_p[p, ...], ths)\nx_cur = torch.mean(p_p.clone(), axis=0)\n\n# Reflective step\nfor p in range(len(list_prox)):\n    z_p[p, ...] = x_cur + z_p[p, ...].clone() - p_p[p, ...]\n\n\n# Plot after one step\nlist_images = [x_cur[0, :, 90, :, :], x_cur[0, :, :, 108, :], x_cur[0, :, :, :, 90]]\ndinv.utils.plot(\n    list_images,\n    figsize=(6, 2),\n    suptitle=\"Denoised brain volume after one step\",\n    cmap=\"viridis\",\n    tight=False,\n    fontsize=12,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Iterating the Dykstra-like algorithm.\nWe are now ready to iterate this algorithm.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Algorithm parameters\nmax_iter = 5  # Increase this number for better results\nths = noise_level_img * 2.0\n\n# Initialize the first element\nz_p = y.repeat(len(list_prox), *([1] * (len(y.shape))))\np_p = torch.zeros_like(z_p)\nx_cur = p_p.clone()\n\nfor it in range(max_iter):\n    # Average proximal step\n    x_prev = x_cur.clone()\n    for p in range(len(list_prox)):\n        p_p[p, ...] = list_prox[p](z_p[p, ...], ths)\n    x_cur = torch.mean(p_p.clone(), axis=0)\n\n    # Reflective step\n    for p in range(len(list_prox)):\n        z_p[p, ...] = x_cur + z_p[p, ...].clone() - p_p[p, ...]\n\n    # Relative criterion for convergence\n    rel_crit = torch.linalg.norm((x_cur - x_prev).flatten()) / torch.linalg.norm(\n        x_cur.flatten() + 1e-6\n    )\n\n\n# Compute the PSNR\npsnr = dinv.metric.PSNR()(x, x_cur).item()\n\n# Plot the output\nlist_images = [x_cur[0, :, 90, :, :], x_cur[0, :, :, 108, :], x_cur[0, :, :, :, 90]]\ndinv.utils.plot(\n    list_images,\n    figsize=(6, 2),\n    suptitle=\"Denoised brain volume after 10 steps. PSNR = {:.2f}dB\".format(psnr),\n    cmap=\"viridis\",\n    tight=False,\n    fontsize=12,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the Dykstra-like algorithm for wavelet denoising.\nYou can readily use this algorithm via the :class:`deepinv.models.WaveletDictDenoiser` class.\n\n::\n\n      y = physics(x)\n      model = dinv.models.WaveletDictDenoiser(list_wv=[\"db8\", \"db4\"], max_iter=10, non_linearity=\"soft\", wvdim=3)\n      xhat = model(y, ths)\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
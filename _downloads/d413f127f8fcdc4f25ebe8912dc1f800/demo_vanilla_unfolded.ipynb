{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Vanilla Unfolded algorithm for super-resolution\n\nThis is a simple example to show how to use vanilla unfolded Plug-and-Play.\nThe DnCNN denoiser and the algorithm parameters (stepsize, regularization parameters) are trained jointly.\nFor simplicity, we show how to train the algorithm on a  small dataset. For optimal results, use a larger dataset.\nFor visualizing the training, you can use Weight&Bias (wandb) by setting ``wandb_vis=True``.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom pathlib import Path\nimport torch\nfrom torch.utils.data import DataLoader\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.optim.prior import PnP\nfrom deepinv.unfolded import unfolded_builder\nfrom torchvision import transforms\nfrom deepinv.utils.demo import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nRESULTS_DIR = BASE_DIR / \"results\"\nCKPT_DIR = BASE_DIR / \"ckpts\"\n\n# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load base image datasets and degradation operators.\nIn this example, we use the CBSD500 dataset for training and the Set3C dataset for testing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img_size = 64 if torch.cuda.is_available() else 32\nn_channels = 3  # 3 for color images, 1 for gray-scale images\noperation = \"super-resolution\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a dataset of low resolution images and load it.\nWe use the Downsampling class from the physics module to generate a dataset of low resolution images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For simplicity, we use a small dataset for training.\n# To be replaced for optimal results. For example, you can use the larger \"drunet\" dataset.\ntrain_dataset_name = \"CBSD500\"\ntest_dataset_name = \"set3c\"\n# Specify the  train and test transforms to be applied to the input images.\ntest_transform = transforms.Compose(\n    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n)\ntrain_transform = transforms.Compose(\n    [transforms.RandomCrop(img_size), transforms.ToTensor()]\n)\n# Define the base train and test datasets of clean images.\ntrain_base_dataset = load_dataset(train_dataset_name, transform=train_transform)\ntest_base_dataset = load_dataset(test_dataset_name, transform=test_transform)\n\n# Use parallel dataloader if using a GPU to fasten training, otherwise, as all computes are on CPU, use synchronous\n# dataloading.\nnum_workers = 4 if torch.cuda.is_available() else 0\n\n# Degradation parameters\nfactor = 2\nnoise_level_img = 0.03\n\n# Generate the gaussian blur downsampling operator.\nphysics = dinv.physics.Downsampling(\n    filter=\"gaussian\",\n    img_size=(n_channels, img_size, img_size),\n    factor=factor,\n    device=device,\n    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n)\nmy_dataset_name = \"demo_unfolded_sr\"\nn_images_max = (\n    1000 if torch.cuda.is_available() else 10\n)  # maximal number of images used for training\nmeasurement_dir = DATA_DIR / train_dataset_name / operation\ngenerated_datasets_path = dinv.datasets.generate_dataset(\n    train_dataset=train_base_dataset,\n    test_dataset=test_base_dataset,\n    physics=physics,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    num_workers=num_workers,\n    dataset_filename=str(my_dataset_name),\n)\n\ntrain_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)\ntest_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the unfolded PnP algorithm.\nWe use the helper function :func:`deepinv.unfolded.unfolded_builder` to defined the Unfolded architecture.\nThe chosen algorithm is here DRS (Douglas-Rachford Splitting).\nNote that if the prior (resp. a parameter) is initialized with a list of lenght max_iter,\nthen a distinct model (resp. parameter) is trained for each iteration.\nFor fixed trained model prior (resp. parameter) across iterations, initialize with a single element.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Unrolled optimization algorithm parameters\nmax_iter = 5  # number of unfolded layers\n\n# Select the data fidelity term\ndata_fidelity = L2()\n\n# Set up the trainable denoising prior\n# Here the prior model is common for all iterations\nprior = PnP(denoiser=dinv.models.DnCNN(depth=7, pretrained=None).to(device))\n\n# The parameters are initialized with a list of length max_iter, so that a distinct parameter is trained for each iteration.\nstepsize = [1] * max_iter  # stepsize of the algorithm\nsigma_denoiser = [0.01] * max_iter  # noise level parameter of the denoiser\nbeta = 1  # relaxation parameter of the Douglas-Rachford splitting\nparams_algo = {  # wrap all the restoration parameters in a 'params_algo' dictionary\n    \"stepsize\": stepsize,\n    \"g_param\": sigma_denoiser,\n    \"beta\": beta,\n}\ntrainable_params = [\n    \"g_param\",\n    \"stepsize\",\n    \"beta\",\n]  # define which parameters from 'params_algo' are trainable\n\n# Logging parameters\nverbose = True\nwandb_vis = False  # plot curves and images in Weight&Bias\n\n# Define the unfolded trainable model.\nmodel = unfolded_builder(\n    iteration=\"DRS\",\n    params_algo=params_algo.copy(),\n    trainable_params=trainable_params,\n    data_fidelity=data_fidelity,\n    max_iter=max_iter,\n    prior=prior,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the training parameters.\nWe use the Adam optimizer and the StepLR scheduler.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# training parameters\nepochs = 10 if torch.cuda.is_available() else 2\nlearning_rate = 5e-4\ntrain_batch_size = 32 if torch.cuda.is_available() else 1\ntest_batch_size = 3\n\n# choose optimizer and scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8))\n\n# choose supervised training loss\nlosses = [dinv.loss.SupLoss(metric=dinv.metric.MSE())]\n\ntrain_dataloader = DataLoader(\n    train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True\n)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the network\nWe train the network using the :class:`deepinv.Trainer` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer = dinv.Trainer(\n    model,\n    physics=physics,\n    train_dataloader=train_dataloader,\n    eval_dataloader=test_dataloader,\n    epochs=epochs,\n    scheduler=scheduler,\n    losses=losses,\n    optimizer=optimizer,\n    device=device,\n    save_path=str(CKPT_DIR / operation),\n    verbose=verbose,\n    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n    wandb_vis=wandb_vis,  # training visualization can be done in Weight&Bias\n)\n\nmodel = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the network\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.test(test_dataloader)\n\ntest_sample, _ = next(iter(test_dataloader))\nmodel.eval()\ntest_sample = test_sample.to(device)\n\n# Get the measurements and the ground truth\ny = physics(test_sample)\nwith torch.no_grad():\n    rec = model(y, physics=physics)\n\nbackprojected = physics.A_adjoint(y)\n\ndinv.utils.plot(\n    [backprojected, rec, test_sample],\n    titles=[\"Linear\", \"Reconstruction\", \"Ground truth\"],\n    suptitle=\"Reconstruction results\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the weights of the network.\n\nWe now plot the weights of the network that were learned and check that they are different from their initialization\nvalues. Note that ``g_param`` corresponds to $\\lambda$ in the proximal gradient algorithm.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dinv.utils.plotting.plot_parameters(\n    model, init_params=params_algo, save_dir=RESULTS_DIR / \"unfolded_pgd\" / operation\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
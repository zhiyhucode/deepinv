{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Saving and loading models\n\nModels can be saved and loaded in the same way as in PyTorch. In this example, we show how to define, load and save a\nmodel. For the purpose of the example, we choose an unfolded Chambolle Pock algorithm as the model.\nThe architecture of the model and its training are described\nin the [constrained unfolded demo](https://deepinv.github.io/deepinv/auto_examples/unfolded/demo_unfolded_constrained_LISTA.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import importlib.util\nfrom pathlib import Path\nimport torch\n\nimport deepinv as dinv\nfrom deepinv.optim.data_fidelity import IndicatorL2\nfrom deepinv.optim.prior import PnP\nfrom deepinv.unfolded import unfolded_builder\nfrom deepinv.models.utils import get_weights_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nRESULTS_DIR = BASE_DIR / \"results\"\nDEG_DIR = BASE_DIR / \"degradations\"\nCKPT_DIR = BASE_DIR / \"ckpts\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define a forward operator\nWe define a simple inpainting operator with 50% of missing pixels.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_channels = 3\nimg_size = 32\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n\n# Define the physics model\nphysics = dinv.physics.Inpainting(\n    (n_channels, img_size, img_size), mask=0.5, device=device\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define a model\nFor the purpose of this example, we define a rather complex model that consists an unfolded Chambolle-Pock algorithm.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Select the data fidelity term\ndata_fidelity = IndicatorL2(radius=0.0)\n\n# Set up the trainable denoising prior; here, the soft-threshold in a wavelet basis.\n# If the prior is initialized with a list of length max_iter,\n# then a distinct weight is trained for each CP iteration.\n# For fixed trained model prior across iterations, initialize with a single model.\n\nlevel = 3\nmax_iter = 20  # Number of unrolled iterations\n\nprior = [\n    PnP(denoiser=dinv.models.WaveletDenoiser(wv=\"db8\", level=level, device=device))\n    for i in range(max_iter)\n]\n\n# Unrolled optimization algorithm parameters\nlamb = [\n    1.0\n] * max_iter  # initialization of the regularization parameter. A distinct lamb is trained for each iteration.\nstepsize = [\n    1.0\n] * max_iter  # initialization of the stepsizes. A distinct stepsize is trained for each iteration.\nsigma_denoiser = [0.01 * torch.ones(level, 3)] * max_iter\n\nsigma = 1.0  # stepsize for Chambolle-Pock\n\nparams_algo = {\n    \"stepsize\": stepsize,\n    \"g_param\": sigma_denoiser,\n    \"lambda\": lamb,\n    \"sigma\": sigma,\n    \"K\": physics.A,\n    \"K_adjoint\": physics.A_adjoint,\n}\n\ntrainable_params = [\n    \"g_param\",\n    \"stepsize\",\n]  # define which parameters from 'params_algo' are trainable\n\n\n# Because the CP algorithm uses more than 2 variables, we need to define a custom initialization.\ndef custom_init_CP(y, physics):\n    x_init = physics.A_adjoint(y)\n    u_init = y\n    return {\"est\": (x_init, x_init, u_init)}\n\n\n# Define the unfolded trainable model.\nmodel = unfolded_builder(\n    \"CP\",\n    trainable_params=trainable_params,\n    params_algo=params_algo,\n    data_fidelity=data_fidelity,\n    max_iter=max_iter,\n    prior=prior,\n    g_first=False,\n    custom_init=custom_init_CP,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving the model\nWe can save the trained model following the standard PyTorch procedure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Save the model\n\ntorch.save(model.state_dict(), CKPT_DIR / \"inpainting/model_nontrained.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the model\nSimilarly, we can load our trained unfolded architecture following the standard PyTorch procedure.\nThis network was trained in the demo `sphx_glr_auto_examples_unfolded_demo_unfolded_constrained_LISTA.py`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set up the trainable denoising prior; here, the soft-threshold in a wavelet basis.\n# If the prior is initialized with a list of length max_iter,\n# then a distinct weight is trained for each PGD iteration.\n# For fixed trained model prior across iterations, initialize with a single model.\n\nprior_new = [\n    PnP(denoiser=dinv.models.WaveletDenoiser(wv=\"db8\", level=level, device=device))\n    for i in range(max_iter)\n]\n\n# Unrolled optimization algorithm parameters\nlamb = [\n    1.0\n] * max_iter  # initialization of the regularization parameter. A distinct lamb is trained for each iteration.\nstepsize = [\n    1.0\n] * max_iter  # initialization of the stepsizes. A distinct stepsize is trained for each iteration.\nsigma_denoiser = [0.01 * torch.ones(level, 3)] * max_iter\n\nsigma = 1.0  # stepsize for Chambolle-Pock\n\nparams_algo_new = {\n    \"stepsize\": stepsize,\n    \"g_param\": sigma_denoiser,\n    \"lambda\": lamb,\n    \"sigma\": sigma,\n    \"K\": physics.A,\n    \"K_adjoint\": physics.A_adjoint,\n}\n\nmodel_new = unfolded_builder(\n    \"CP\",\n    trainable_params=trainable_params,\n    params_algo=params_algo_new,\n    data_fidelity=data_fidelity,\n    max_iter=max_iter,\n    prior=prior_new,\n    g_first=False,\n    custom_init=custom_init_CP,\n)\nprint(\n    \"Parameter model_new.params_algo.g_param[0] at init: \\n\",\n    model_new.params_algo.g_param[0],\n)\n\n\n# load a state_dict checkpoint\nfile_name = (\n    \"demo_unfolded_CP_ptwt.pth\"\n    if importlib.util.find_spec(\"ptwt\")\n    else \"demo_unfolded_CP.pth\"\n)\nurl = get_weights_url(model_name=\"demo\", file_name=file_name)\nckpt_state_dict = torch.hub.load_state_dict_from_url(\n    url, map_location=lambda storage, loc: storage, file_name=file_name\n)\n\n# load a state_dict checkpoint\nmodel_new.load_state_dict(ckpt_state_dict)\n\nprint(\n    \"Parameter model_new.params_algo.g_param[0] after loading: \\n\",\n    model_new.params_algo.g_param[0],\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
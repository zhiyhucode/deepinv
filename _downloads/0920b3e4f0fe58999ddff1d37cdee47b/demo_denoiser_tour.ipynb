{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# A tour of DeepInv's denoisers\n\nThis example provides a tour of the denoisers in DeepInv.\nA denoiser is a model that takes in a noisy image and outputs a denoised version of it.\nBasically, it solves the following problem:\n\n\\begin{align}\\underset{x}{\\min}\\|x -  \\denoiser{x + \\sigma \\epsilon}{\\sigma}\\|_2^2.\\end{align}\n\nThe denoisers in DeepInv comes with different flavors, depending on whether they are derived from\nanalytical image processing techniques or learned from data.\nThis example will show how to use the different denoisers in DeepInv, compare their performances,\nand highlights the different tradeoffs they offer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport deepinv as dinv\nfrom deepinv.utils.plotting import plot_inset\nfrom deepinv.utils.demo import load_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load test images\n\nFirst, let's load a test image to illustrate the denoisers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dtype = torch.float32\ndevice = \"cpu\"\nimg_size = (173, 125)\n\nimage = load_example(\n    \"CBSD_0010.png\", grayscale=False, device=device, dtype=dtype, img_size=img_size\n)\n\n# Next, set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\n\n# Finally, create a noisy version of the image with a fixed noise level sigma.\nsigma = 0.2\nnoisy_image = image + sigma * torch.randn_like(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this tour, we define an helper function to display comparison of various\nrestored images, with their PSNR values and zoom-in on a region of interest.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def show_image_comparison(images, suptitle=None, ref=None):\n    \"\"\"Display various images restoration with PSNR and zoom-in\"\"\"\n\n    titles = list(images.keys())\n    if \"Original\" in images or ref is not None:\n        # If the original image is in the dict, add PSNR in the titles.\n        image = images[\"Original\"] if \"Original\" in images else ref\n        psnr = [dinv.metric.cal_psnr(image, im).item() for im in images.values()]\n        titles = [\n            f\"{name} \\n (PSNR: {psnr:.2f})\" if name != \"Original\" else name\n            for name, psnr in zip(images.keys(), psnr)\n        ]\n    # Plot the images with zoom-in\n    fig = plot_inset(\n        list(images.values()),\n        titles=titles,\n        extract_size=0.2,\n        extract_loc=(0.5, 0.0),\n        inset_size=0.5,\n        return_fig=True,\n        show=False,\n        figsize=(len(images) * 1.5, 2.5),\n    )\n\n    # Add a suptitle if it is provided\n    if suptitle:\n        plt.suptitle(suptitle, size=12)\n        plt.tight_layout()\n        fig.subplots_adjust(top=0.85, bottom=0.02, left=0.02, right=0.95)\n        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now ready to explore the different denoisers.\n\n## Classical Denoisers\n\nDeepInv provides a set of classical denoisers such as :class:`deepinv.models.BM3D`,\n:class:`deepinv.models.TGVDenoiser`, or :class:`deepinv.models.WaveletDictDenoiser`.\n\nThey can be easily used simply by instanciating their corresponding class,\nand calling them with the noisy image and the noise level.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bm3d = dinv.models.BM3D()\ntgv = dinv.models.TGVDenoiser()\nwavelet = dinv.models.WaveletDictDenoiser()\n\ndenoiser_results = {\n    \"Original\": image,\n    \"Noisy\": noisy_image,\n    \"BM3D\": bm3d(noisy_image, sigma),\n    \"TGV\": tgv(noisy_image, sigma),\n    \"Wavelet\": wavelet(noisy_image, sigma),\n}\nshow_image_comparison(denoiser_results, suptitle=rf\"Noise level $\\sigma={sigma:.2f}$\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deep Denoisers\n\nDeepInv also provides a set of deep denoisers.\nMost of these denoisers are available with pretrained weights, so they can be used readily.\nTo instantiate them, you can simply call their corresponding class with default\nparameters and ``pretrained=\"download\"`` to load their weights.\nYou can then apply them by calling the model with the noisy image and the noise level.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dncnn = dinv.models.DnCNN()\ndrunet = dinv.models.DRUNet()\nswinir = dinv.models.SwinIR()\nscunet = dinv.models.SCUNet()\n\ndenoiser_results = {\n    \"Original\": image,\n    \"Noisy\": noisy_image,\n    \"DnCNN\": dncnn(noisy_image, sigma),\n    \"DRUNet\": drunet(noisy_image, sigma),\n    \"SCUNet\": scunet(noisy_image, sigma),\n    \"SwinIR\": swinir(noisy_image, sigma),\n}\nshow_image_comparison(denoiser_results, suptitle=rf\"Noise level $\\sigma={sigma:.2f}$\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing denoisers\n\nAs we have seen, these denoisers don't have the same training or expected behavior depending on\nthe noise level. Indeed, there are three classes of denoisers:\n\n- *Fixed-noise level denoisers:* Some denoisers are trained to be able to recover\n  images from noisy input with a fixed noise levels. Typically, this is the case\n  of :class:`deepinv.models.DnCNN` or :class:`deepinv.models.SwinIR`.\n- *Adaptive-level denoisers:* These denoisers are able to adapt to the noise level\n  of a given image. Basically, these denoisers' performance vary strognly with the\n  value ``sigma`` given as an input. This is typically the case for :class:`deepinv.models.BM3D`,\n  :class:`deepinv.models.SCUNet`, or :class:`deepinv.models.DRUNet`, but also for denoisers based on regularisations\n  like :class:`deepinv.models.WaveletDictDenoiser`.\n  A typical caveat of regularisation-based denoisers is that the second parameter doesn't\n  correspond to ``sigma`` but to a threshold value, which needs to be adapted to the noise level.\n- *Blind denoisers:* These denoisers estimate the level of noise in the input image\n  to output the cleanest image possible. Example of blind denoisers are :class:`deepinv.models.SCUNet`\n  or :class:`deepinv.models.Restormer`.\n\nLet us generate a set of noisy images with varying noise levels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "noise_levels = torch.logspace(-2, 0, 9)\nnoise = torch.randn((len(noise_levels), *image.shape[1:]))\nnoisy_images = image + noise_levels[:, None, None, None] * noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first record the PSNR of the noisy images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "psnr = dinv.loss.metric.PSNR()\npsnr_x = psnr(noisy_images, image)\nres = [\n    {\"sigma\": sig.item(), \"denoiser\": \"Noisy\", \"psnr\": v.item(), \"time\": 0.0}\n    for sig, v in zip(noise_levels, psnr_x)\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we evaluate the various denoisers with our set of varying noise level.\nNote that to minimize the computation time, we evaluate the performances in\nbatch, by passing all the noisy images at once to the denoiser, with varying\nnoise levels for each entry in the batch.\n\nWe also store the runtime of each denoiser to evaluate the tradeoff between computation\ntime and performances.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "denoisers = {\n    \"DRUNet\": drunet,\n    # 'SwinIR': sinwir, # SwinIR is slow for this example, skipping it in the doc\n    \"SCUNet\": scunet,\n    \"DnCNN\": dncnn,\n    \"BM3D\": bm3d,\n    \"Wavelet\": wavelet,\n}\n\nfor name, d in denoisers.items():\n    print(f\"Denoiser {name}...\", end=\"\", flush=True)\n    t_start = time.perf_counter()\n    with torch.no_grad():\n        clean_images = d(noisy_images, noise_levels)\n        psnr_x = psnr(clean_images, image)\n    runtime = time.perf_counter() - t_start\n    res.extend(\n        [\n            {\"sigma\": sig.item(), \"denoiser\": name, \"psnr\": v.item(), \"time\": runtime}\n            for sig, v in zip(noise_levels, psnr_x)\n        ]\n    )\n    print(f\" done ({runtime:.2f}s)\")\ndf = pd.DataFrame(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now compare the performances of the different denoisers.\nWe plot the PSNR of the denoised images as a function of the noise level\nfor each denoiser.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "styles = {\n    \"Noisy\": dict(ls=\"--\", color=\"black\"),\n}\ngroups = df.groupby(\"denoiser\")\n_, ax = plt.subplots(figsize=(6, 4))\nfor name, g in groups:\n    g.plot(x=r\"sigma\", y=\"psnr\", label=name, ax=ax, **styles.get(name, {}))\nax.set_xscale(\"log\")\nax.set_xlabel(r\"$\\sigma$\")\nax.set_ylabel(\"PSNR\")\nplt.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\", borderaxespad=0)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that overall :class:`deepinv.models.DRUNet` achieves the best performances for all\nnoise levels. It also achieves a good tradeoff between computation time and performances.\n\n## Tuning regularisation-based denoisers\n\nNote that the performances of denoisers that are based on regularisation,\nlike :class:`deepinv.models.WaveletDictDenoiser`, are not well adapted to the noise level.\nIndeed, the second parameter of these denoisers is ``th``, which does not directly match the\nnoise level ``sigma``. We will now show how to tune the threshold to match the noise level.\n\nFirst we start by evaluating the performances of the wavelet denoiser for a grid of threshold\nvalues on the noisy images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "wavelets = dinv.models.WaveletDictDenoiser()\nthresholds = torch.logspace(-3, 1, 13)\n\nres = []\nfor th in thresholds:\n    t_start = time.perf_counter()\n    clean_images = wavelets(noisy_images, th.item())\n    runtime = time.perf_counter() - t_start\n    res.extend(\n        {\n            \"psnr\": psnr(clean_img[None], image).item(),\n            \"sigma\": sig.item(),\n            \"th\": th.item(),\n            \"time\": runtime,\n        }\n        for sig, clean_img in zip(noise_levels, clean_images)\n    )\ndf_wavelet = pd.DataFrame(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now display how the performances vary with the value of the threshold,\nand what is the best threshold for each noise level.\nsphinx_gallery_thumbnail_number = 3\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "groups = df_wavelet.groupby(\"sigma\")[[\"sigma\", \"psnr\", \"th\"]]\nbest_th_psnr = groups.apply(lambda g: g.loc[g[\"psnr\"].idxmax()])\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 4))\ncmap = plt.get_cmap(\"viridis\")\nnorm = plt.cm.colors.LogNorm(\n    vmin=df_wavelet[\"sigma\"].min(), vmax=df_wavelet[\"sigma\"].max()\n)\nfor sig, group in groups:\n    group.plot(x=\"th\", y=\"psnr\", ax=axes[0], color=cmap(norm(sig)), label=None)\naxes[0].set_xscale(\"log\")\naxes[0].set_ylabel(\"Threshold\")\naxes[0].set_ylabel(\"PSNR\")\naxes[0].legend([])\nfig.colorbar(\n    plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n    label=r\"$\\sigma$\",\n    location=\"top\",\n    ax=axes[0],\n)\n\naxes[1].set_title(\"Best threshold for each noise level\")\naxes[1].loglog(best_th_psnr[\"sigma\"], best_th_psnr[\"th\"], marker=\"o\")\naxes[1].set_xlabel(r\"$\\sigma$\")\naxes[1].set_ylabel(r\"Best threshold\")\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With this tuning, we can update our comparison of the different denoisers to account for\nthe performances of :class:`deepinv.models.WaveletDictDenoiser` once the threshold have been tuned\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "merge_df = best_th_psnr.reset_index(drop=True).drop(columns=\"th\")\nmerge_df[\"denoiser\"] = \"Wavelet (tuned)\"\nmerge_df = pd.concat([df.query(\"denoiser != 'Wavelet'\"), merge_df])\n\n_, ax = plt.subplots(figsize=(6, 4))\nfor name, g in merge_df.groupby(\"denoiser\"):\n    g.plot(x=r\"sigma\", y=\"psnr\", label=name, ax=ax, **styles.get(name, {}))\nax.set_xscale(\"log\")\nax.set_xlabel(r\"$\\sigma$\")\nax.set_ylabel(\"PSNR\")\nplt.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\", borderaxespad=0)\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adapting fixed-noise level denoisers\n\nFor fixed-noise level denoiser, we also see poor performances, since these models were trained\nfor a given noise level which does not correspond to the noise level of the input image. See\n`pretrained-weights <pretrained-weights>` for more details on the chose noise level.\nA way to improve the performance of these models is to artificially rescale the input image\nto match the training noise level.\nWe can define a wrapper that automatically applies this rescaling.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class AdaptedDenoiser:\n    r\"\"\"\n    This function rescales the input image to match the noise level of the model,\n    applies the denoiser, and then rescales the output to the original noise level.\n    \"\"\"\n\n    def __init__(self, model, sigma_train):\n        self.model = model\n        self.sigma_train = sigma_train\n\n    def __call__(self, image, sigma):\n        if isinstance(sigma, torch.Tensor):\n            # If sigma is a tensor, we assume it is one value per element in the batch\n            assert len(sigma) == image.shape[0]\n            sigma = sigma[:, None, None, None]\n\n        # Rescale the output to match the original noise level\n        rescaled_image = image / sigma * self.sigma_train\n        with torch.no_grad():\n            output = self.model(rescaled_image, self.sigma_train)\n        output = output * sigma / self.sigma_train\n        return output\n\n\n# Apply to DnCNN and SwinIR\nsigma_train_dncnn = 2.0 / 255.0\nadapted_dncnn = AdaptedDenoiser(dncnn, sigma_train_dncnn)\n\n# Apply SwinIR\n# sigma_train_swinir = 15.0 / 255.0\n# adapted_swinir = AdaptedDenoiser(swinir, sigma_train_swinir)\n\n# sphinx_gallery_multi_image = \"single\"\ndenoiser_results = {\n    f\"Original\": image,\n    f\"Noisy\": noisy_image,\n    f\"DnCNN\": dncnn(noisy_image, sigma),\n    f\"DnCNN (adapted)\": adapted_dncnn(noisy_image, sigma),\n}\nshow_image_comparison(denoiser_results, suptitle=rf\"Noise level $\\sigma={sigma:.2f}$\")\n\ndenoiser_results = {\n    # Skipping SwinIR on CI due to high memory usage\n    # f\"SwinIR\": swinir(noisy_image, sigma),\n    # f\"SwinIR (adapted)\": adapted_swinir(noisy_image, sigma),\n    f\"DRUNet\": drunet(noisy_image, sigma),\n    f\"SCUNet\": scunet(noisy_image, sigma),\n}\nshow_image_comparison(\n    denoiser_results, ref=image, suptitle=rf\"Noise level $\\sigma={sigma:.2f}$\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can finally update our comparison with the adapted denoisers for DnCNN and SwinIR.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adapted_denoisers = {\n    # \"SwinIR\": adapted_swinir, # SwinIR is slow for this example, skipping it in the doc\n    \"DnCNN (adapted)\": adapted_dncnn,\n}\nres = []\nfor name, d in adapted_denoisers.items():\n    print(f\"Denoiser {name}...\", end=\"\", flush=True)\n    t_start = time.perf_counter()\n    with torch.no_grad():\n        clean_images = d(noisy_images, noise_levels)\n        psnr_x = psnr(clean_images, image)\n    runtime = time.perf_counter() - t_start\n    res.extend(\n        [\n            {\"sigma\": sig.item(), \"denoiser\": name, \"psnr\": v.item(), \"time\": runtime}\n            for sig, v in zip(noise_levels, psnr_x)\n        ]\n    )\n    print(f\" done ({runtime:.2f}s)\")\ndf_adapted = pd.DataFrame(res)\nmerge_df = pd.concat(\n    [merge_df.query(\"~denoiser.isin(['DnCNN', 'SwinIR'])\"), df_adapted]\n)\n\n_, ax = plt.subplots(figsize=(6, 4))\nfor name, g in merge_df.groupby(\"denoiser\"):\n    g.plot(x=r\"sigma\", y=\"psnr\", label=name, ax=ax, **styles.get(name, {}))\nax.set_xscale(\"log\")\nax.set_xlabel(r\"$\\sigma$\")\nax.set_ylabel(\"PSNR\")\nplt.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\", borderaxespad=0)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the adapted denoisers achieve better performances than the original ones,\nbut they are still not as good as DRUNet which is trained for a wide range of noise levels.\n\nFinally, we can also compare the tradeoff between computation time and performances of the different denoisers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12, 6))\ngrid = plt.GridSpec(2, 2, height_ratios=[0.25, 0.75])\nfor i, sig in enumerate(noise_levels[[0, 4]]):\n    ax = fig.add_subplot(grid[1, i])\n    to_plot = merge_df.query(f\"sigma == {sig}\")\n    handles = []\n    for name, g in to_plot.groupby(\"denoiser\"):\n        handles.append(ax.scatter(g[\"time\"], g[\"psnr\"], label=name))\n    ax.set_title(rf\"$\\sigma={sig:.2f}$\")\n    ax.set_xscale(\"log\")\n    ax.set_xlabel(\"Time (s)\")\n    ax.set_ylabel(\"PSNR\")\n\nax_legend = fig.add_subplot(grid[0, :])\nax_legend.legend(handles=handles, ncol=3, loc=\"center\")\nax_legend.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that depending on the noise-level, the tadeoff between computation time\nand performances changes, with the deep denoisers performing the best\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Training a reconstruction network.\n\nThis example shows how to train a simple reconstruction network for an image\ninpainting inverse problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom torch.utils.data import DataLoader\nimport torch\nfrom pathlib import Path\nfrom torchvision import transforms\nfrom deepinv.utils.demo import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nCKPT_DIR = BASE_DIR / \"ckpts\"\n\n# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load base image datasets and degradation operators.\nIn this example, we use the CBSD68 dataset for training and the set3c dataset for testing.\nWe work with images of size 32x32 if no GPU is available, else 128x128.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "operation = \"inpainting\"\ntrain_dataset_name = \"CBSD68\"\ntest_dataset_name = \"set3c\"\nimg_size = 128 if torch.cuda.is_available() else 32\n\ntest_transform = transforms.Compose(\n    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n)\ntrain_transform = transforms.Compose(\n    [transforms.RandomCrop(img_size), transforms.ToTensor()]\n)\n\ntrain_dataset = load_dataset(train_dataset_name, train_transform)\ntest_dataset = load_dataset(test_dataset_name, test_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define forward operator and generate dataset\nWe define an inpainting operator that randomly masks pixels with probability 0.5.\n\nA dataset of pairs of measurements and ground truth images is then generated using the\n:func:`deepinv.datasets.generate_dataset` function.\n\nOnce the dataset is generated, we can load it using the :class:`deepinv.datasets.HDF5Dataset` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_channels = 3  # 3 for color images, 1 for gray-scale images\nprobability_mask = 0.5  # probability to mask pixel\n\n# Generate inpainting operator\nphysics = dinv.physics.Inpainting(\n    img_size=(n_channels, img_size, img_size), mask=probability_mask, device=device\n)\n\n\n# Use parallel dataloader if using a GPU to fasten training,\n# otherwise, as all computes are on CPU, use synchronous data loading.\nnum_workers = 4 if torch.cuda.is_available() else 0\nn_images_max = (\n    1000 if torch.cuda.is_available() else 50\n)  # maximal number of images used for training\nmy_dataset_name = \"demo_training_inpainting\"\nmeasurement_dir = DATA_DIR / train_dataset_name / operation\ndeepinv_datasets_path = dinv.datasets.generate_dataset(\n    train_dataset=train_dataset,\n    test_dataset=test_dataset,\n    physics=physics,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    num_workers=num_workers,\n    dataset_filename=str(my_dataset_name),\n)\n\ntrain_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)\ntest_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)\n\n\ntrain_batch_size = 32 if torch.cuda.is_available() else 1\ntest_batch_size = 32 if torch.cuda.is_available() else 1\n\ntrain_dataloader = DataLoader(\n    train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True\n)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the reconstruction network\nWe use a simple inversion architecture of the form\n\n     .. math::\n\n              f_{\\theta}(y) = \\phi_{\\theta}(A^{\\top}(y))\n\nwhere the linear reconstruction $A^{\\top}y$ is post-processed by a U-Net network $\\phi_{\\theta}$ is a\nneural network with trainable parameters $\\theta$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# choose backbone model\nbackbone = dinv.models.UNet(\n    in_channels=3, out_channels=3, scales=3, batch_norm=False\n).to(device)\n\n# choose a reconstruction architecture\nmodel = dinv.models.ArtifactRemoval(backbone)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\nWe train the model using the :class:`deepinv.Trainer` class.\n\nWe perform supervised learning and use the mean squared error as loss function. This can be easily done using the\n:class:`deepinv.loss.SupLoss` class.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In this example, we only train for a few epochs to keep the training time short.\n      For a good reconstruction quality, we recommend to train for at least 100 epochs.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "verbose = True  # print training information\nwandb_vis = False  # plot curves and images in Weight&Bias\n\nepochs = 4  # choose training epochs\nlearning_rate = 5e-4\n\n# choose training losses\nlosses = dinv.loss.SupLoss(metric=dinv.metric.MSE())\n\n# choose optimizer and scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8))\ntrainer = dinv.Trainer(\n    model,\n    device=device,\n    save_path=str(CKPT_DIR / operation),\n    verbose=verbose,\n    wandb_vis=wandb_vis,\n    physics=physics,\n    epochs=epochs,\n    scheduler=scheduler,\n    losses=losses,\n    optimizer=optimizer,\n    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n    train_dataloader=train_dataloader,\n    eval_dataloader=test_dataloader,\n)\ntrainer.train()\n# load model with best validation PSNR\nmodel = trainer.load_best_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the network\nWe can now test the trained network using the :func:`deepinv.test` function.\n\nThe testing function will compute test_psnr metrics and plot and save the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.test(test_dataloader)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/sampling/demo_dps.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_sampling_demo_dps.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_sampling_demo_dps.py:


Implementing DPS
================

In this tutorial, we will go over the steps in the Diffusion Posterior Sampling (DPS) algorithm introduced in
`Chung et al. <https://arxiv.org/abs/2209.14687>`_ The full algorithm is implemented in
:class:`deepinv.sampling.DPS`.

.. GENERATED FROM PYTHON SOURCE LINES 11-20

Installing dependencies
-----------------------
Let us ``import`` the relevant packages, and load a sample
image of size 64 x 64. This will be used as our ground truth image.

.. note::
          We work with an image of size 64 x 64 to reduce the computational time of this example.
          The algorithm works best with images of size 256 x 256.


.. GENERATED FROM PYTHON SOURCE LINES 20-35

.. code-block:: Python


    import numpy as np
    import torch

    import deepinv as dinv
    from deepinv.utils.plotting import plot
    from deepinv.optim.data_fidelity import L2
    from deepinv.utils.demo import load_example
    from tqdm import tqdm  # to visualize progress

    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"

    x_true = load_example("butterfly.png", img_size=64).to(device)
    x = x_true.clone()








.. GENERATED FROM PYTHON SOURCE LINES 36-39

In this tutorial we consider random inpainting as the inverse problem, where the forward operator is implemented
in :class:`deepinv.physics.Inpainting`. In the example that we use, 90% of the pixels will be masked out randomly,
and we will additionally have Additive White Gaussian Noise (AWGN) of standard deviation  12.75/255.

.. GENERATED FROM PYTHON SOURCE LINES 39-58

.. code-block:: Python


    sigma = 12.75 / 255.0  # noise level

    physics = dinv.physics.Inpainting(
        img_size=(3, x.shape[-2], x.shape[-1]),
        mask=0.1,
        pixelwise=True,
        device=device,
    )

    y = physics(x_true)

    imgs = [y, x_true]
    plot(
        imgs,
        titles=["measurement", "groundtruth"],
    )





.. image-sg:: /auto_examples/sampling/images/sphx_glr_demo_dps_001.png
   :alt: measurement, groundtruth
   :srcset: /auto_examples/sampling/images/sphx_glr_demo_dps_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 59-66

Diffusion model loading
-----------------------

We will take a pre-trained diffusion model that was also used for the DiffPIR algorithm, namely the one trained on
the FFHQ 256x256 dataset. Note that this means that the diffusion model was trained with human face images,
which is very different from the image that we consider in our example. Nevertheless, we will see later on that
``DPS`` generalizes sufficiently well even in such case.

.. GENERATED FROM PYTHON SOURCE LINES 66-70

.. code-block:: Python



    model = dinv.models.DiffUNet(large_model=False).to(device)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://huggingface.co/deepinv/diffunet/resolve/main/diffusion_ffhq_10m.pt?download=true" to /home/runner/.cache/torch/hub/checkpoints/diffusion_ffhq_10m.pt
      0%|          | 0.00/357M [00:00<?, ?B/s]      9%|▉         | 33.6M/357M [00:00<00:00, 353MB/s]     19%|█▉        | 68.8M/357M [00:00<00:00, 361MB/s]     29%|██▉       | 104M/357M [00:00<00:00, 363MB/s]      39%|███▊      | 138M/357M [00:00<00:00, 350MB/s]     49%|████▊     | 174M/357M [00:00<00:00, 358MB/s]     58%|█████▊    | 208M/357M [00:00<00:00, 360MB/s]     68%|██████▊   | 243M/357M [00:00<00:00, 360MB/s]     78%|███████▊  | 277M/357M [00:00<00:00, 331MB/s]     87%|████████▋ | 309M/357M [00:00<00:00, 307MB/s]     96%|█████████▌| 342M/357M [00:01<00:00, 318MB/s]    100%|██████████| 357M/357M [00:01<00:00, 338MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 71-88

Define diffusion schedule
-------------------------

We will use the standard linear diffusion noise schedule. Once :math:`\beta_t` is defined to follow a linear schedule
that interpolates between :math:`\beta_{\rm min}` and :math:`\beta_{\rm max}`,
we have the following additional definitions:
:math:`\alpha_t := 1 - \beta_t`, :math:`\bar\alpha_t := \prod_{j=1}^t \alpha_j`.
The following equations will also be useful
later on (we always assume that :math:`\mathbf{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})` hereafter.)

.. math::

          \mathbf{x}_t = \sqrt{\beta_t}\mathbf{x}_{t-1} + \sqrt{1 - \beta_t}\mathbf{\epsilon}

          \mathbf{x}_t = \sqrt{\bar\alpha_t}\mathbf{x}_0 + \sqrt{1 - \bar\alpha_t}\mathbf{\epsilon}

where we use the reparametrization trick.

.. GENERATED FROM PYTHON SOURCE LINES 88-111

.. code-block:: Python


    num_train_timesteps = 1000  # Number of timesteps used during training


    def get_betas(
        beta_start=0.1 / 1000, beta_end=20 / 1000, num_train_timesteps=num_train_timesteps
    ):
        betas = np.linspace(beta_start, beta_end, num_train_timesteps, dtype=np.float32)
        betas = torch.from_numpy(betas).to(device)

        return betas


    # Utility function to let us easily retrieve \bar\alpha_t
    def compute_alpha(beta, t):
        beta = torch.cat([torch.zeros(1).to(beta.device), beta], dim=0)
        a = (1 - beta).cumprod(dim=0).index_select(0, t + 1).view(-1, 1, 1, 1)
        return a


    betas = get_betas()









.. GENERATED FROM PYTHON SOURCE LINES 112-146

The DPS algorithm
-----------------

Now that the inverse problem is defined, we can apply the DPS algorithm to solve it. The DPS algorithm is
a diffusion algorithm that alternates between a denoising step, a gradient step and a reverse diffusion sampling step.
The algorithm writes as follows, for :math:`t` decreasing from :math:`T` to :math:`1`:

.. math::
        \begin{equation*}
        \begin{aligned}
        \widehat{\mathbf{x}}_{t} &= \denoiser{\mathbf{x}_t}{\sqrt{1-\overline{\alpha}_t}/\sqrt{\overline{\alpha}_t}}
        \\
        \mathbf{g}_t &= \nabla_{\mathbf{x}_t} \log p( \widehat{\mathbf{x}}_{t}(\mathbf{x}_t) | \mathbf{y} ) \\
        \mathbf{\varepsilon}_t &= \mathcal{N}(0, \mathbf{I}) \\
        \mathbf{x}_{t-1} &= a_t \,\, \mathbf{x}_t
        + b_t \, \, \widehat{\mathbf{x}}_t
        + \tilde{\sigma}_t \, \, \mathbf{\varepsilon}_t + \mathbf{g}_t,
        \end{aligned}
        \end{equation*}

where :math:`\denoiser{\cdot}{\sigma}` is a denoising network for noise level :math:`\sigma`,
:math:`\eta` is a hyperparameter, and the constants :math:`\tilde{\sigma}_t, a_t, b_t` are defined as

.. math::
        \begin{equation*}
        \begin{aligned}
          \tilde{\sigma}_t &= \eta \sqrt{ (1 - \frac{\overline{\alpha}_t}{\overline{\alpha}_{t-1}})
          \frac{1 - \overline{\alpha}_{t-1}}{1 - \overline{\alpha}_t}} \\
          a_t &= \sqrt{1 - \overline{\alpha}_{t-1} - \tilde{\sigma}_t^2}/\sqrt{1-\overline{\alpha}_t} \\
          b_t &= \sqrt{\overline{\alpha}_{t-1}} - \sqrt{1 - \overline{\alpha}_{t-1} - \tilde{\sigma}_t^2}
          \frac{\sqrt{\overline{\alpha}_{t}}}{\sqrt{1 - \overline{\alpha}_{t}}}
        \end{aligned}
        \end{equation*}


.. GENERATED FROM PYTHON SOURCE LINES 149-158

Denoising step
--------------

The first step of DPS consists of applying a denoiser function to the current image :math:`\mathbf{x}_t`,
with standard deviation :math:`\sigma_t = \sqrt{1 - \overline{\alpha}_t}/\sqrt{\overline{\alpha}_t}`.

This is equivalent to sampling :math:`\mathbf{x}_t \sim q(\mathbf{x}_t|\mathbf{x}_0)`, and then computing the
posterior mean.


.. GENERATED FROM PYTHON SOURCE LINES 158-177

.. code-block:: Python



    t = torch.ones(1, device=device) * 200  # choose some arbitrary timestep
    at = compute_alpha(betas, t.long())
    sigmat = (1 - at).sqrt() / at.sqrt()

    x0 = x_true
    xt = x0 + sigmat * torch.randn_like(x0)

    # apply denoiser
    x0_t = model(xt, sigmat)

    # Visualize
    imgs = [x0, xt, x0_t]
    plot(
        imgs,
        titles=["ground-truth", "noisy", "posterior mean"],
    )




.. image-sg:: /auto_examples/sampling/images/sphx_glr_demo_dps_002.png
   :alt: ground-truth, noisy, posterior mean
   :srcset: /auto_examples/sampling/images/sphx_glr_demo_dps_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 178-212

DPS approximation
-----------------

In order to perform gradient-based **posterior sampling** with diffusion models, we have to be able to compute
:math:`\nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t|\mathbf{y})`. Applying Bayes rule, we have

.. math::

          \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t|\mathbf{y}) = \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t)
          + \nabla_{\mathbf{x}_t} \log p(\mathbf{y}|\mathbf{x}_t)

For the former term, we can simply plug-in our estimated score function as in Tweedie's formula. As the latter term
is intractable, DPS proposes the following approximation (for details, see Theorem 1 of
`Chung et al. <https://arxiv.org/abs/2209.14687>`_)

.. math::

          \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t|\mathbf{y}) \approx \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t)
          + \nabla_{\mathbf{x}_t} \log p(\mathbf{y}|\widehat{\mathbf{x}}_{t})

Remarkably, we can now compute the latter term when we have Gaussian noise, as

.. math::

      \log p(\mathbf{y}|\hat{\mathbf{x}}_{t}) =
      -\frac{\|\mathbf{y} - A\widehat{\mathbf{x}}_{t}\|_2^2}{2\sigma_y^2}.

Moreover, taking the gradient w.r.t. :math:`\mathbf{x}_t` can be performed through automatic differentiation.
Let's see how this can be done in PyTorch. Note that when we are taking the gradient w.r.t. a tensor,
we first have to enable the gradient computation by ``tensor.requires_grad_()``

.. note::
          The diffPIR algorithm assumes that the images are in the range [-1, 1], whereas standard denoisers
          usually output images in the range [0, 1]. This is why we rescale the images before applying the steps.

.. GENERATED FROM PYTHON SOURCE LINES 212-244

.. code-block:: Python



    x0 = x_true * 2.0 - 1.0  # [0, 1] -> [-1, 1]

    data_fidelity = L2()

    # xt ~ q(xt|x0)
    i = 200  # choose some arbitrary timestep
    t = (torch.ones(1) * i).to(device)
    at = compute_alpha(betas, t.long())
    sigma_cur = (1 - at).sqrt() / at.sqrt()
    xt = x0 + sigma_cur * torch.randn_like(x0)

    # DPS
    with torch.enable_grad():
        # Turn on gradient
        xt.requires_grad_()

        # normalize to [0,1], denoise, and rescale to [-1, 1]
        x0_t = model(xt / 2 + 0.5, sigma_cur / 2) * 2 - 1
        # Log-likelihood
        ll = data_fidelity(x0_t, y, physics).sqrt().sum()
        # Take gradient w.r.t. xt
        grad_ll = torch.autograd.grad(outputs=ll, inputs=xt)[0]

    # Visualize
    imgs = [x0, xt, x0_t, grad_ll]
    plot(
        imgs,
        titles=["groundtruth", "noisy", "posterior mean", "gradient"],
    )




.. image-sg:: /auto_examples/sampling/images/sphx_glr_demo_dps_003.png
   :alt: groundtruth, noisy, posterior mean, gradient
   :srcset: /auto_examples/sampling/images/sphx_glr_demo_dps_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 245-271

DPS Algorithm
-------------

As we visited all the key components of DPS, we are now ready to define the algorithm. For every denoising
timestep, the algorithm iterates the following

1. Get :math:`\hat{\mathbf{x}}` using the denoiser network.
2. Compute :math:`\nabla_{\mathbf{x}_t} \log p(\mathbf{y}|\hat{\mathbf{x}}_t)` through backpropagation.
3. Perform reverse diffusion sampling with DDPM(IM), corresponding to an update with :math:`\nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t)`.
4. Take a gradient step with :math:`\nabla_{\mathbf{x}_t} \log p(\mathbf{y}|\hat{\mathbf{x}}_t)`.

There are two caveats here. First, in the original work, DPS used DDPM ancestral sampling. As the `DDIM sampler
<https://arxiv.org/abs/2010.02502)>`_ is a generalization of DDPM in a sense that it retrieves DDPM when
:math:`\eta = 1.0`, here we consider DDIM sampling.
One can freely choose the :math:`\eta` parameter here, but since we will consider 1000
neural function evaluations (NFEs),
it is advisable to keep it :math:`\eta = 1.0`. Second, when taking the log-likelihood gradient step,
the gradient is weighted so that the actual implementation is a static step size times the :math:`\ell_2`
norm of the residual:

.. math::

          \nabla_{\mathbf{x}_t} \log p(\mathbf{y}|\hat{\mathbf{x}}_{t}(\mathbf{x}_t)) \simeq
          \rho \nabla_{\mathbf{x}_t} \|\mathbf{y} - \mathbf{A}\hat{\mathbf{x}}_{t}\|_2

With these in mind, let us solve the inverse problem with DPS!

.. GENERATED FROM PYTHON SOURCE LINES 274-279

.. note::

  We only use 200 steps to reduce the computational time of this example. As suggested by the authors of DPS, the
  algorithm works best with ``num_steps = 1000``.


.. GENERATED FROM PYTHON SOURCE LINES 279-351

.. code-block:: Python


    num_steps = 200

    skip = num_train_timesteps // num_steps

    batch_size = 1
    eta = 1.0

    seq = range(0, num_train_timesteps, skip)
    seq_next = [-1] + list(seq[:-1])
    time_pairs = list(zip(reversed(seq), reversed(seq_next)))

    # measurement
    x0 = x_true * 2.0 - 1.0
    # x0 = x_true.clone()
    y = physics(x0.to(device))

    # initial sample from x_T
    x = torch.randn_like(x0)

    xs = [x]
    x0_preds = []

    for i, j in tqdm(time_pairs):
        t = (torch.ones(batch_size) * i).to(device)
        next_t = (torch.ones(batch_size) * j).to(device)

        at = compute_alpha(betas, t.long())
        at_next = compute_alpha(betas, next_t.long())

        xt = xs[-1].to(device)

        with torch.enable_grad():
            xt.requires_grad_()

            # 1. denoising step
            aux_x = xt / (2 * at.sqrt()) + 0.5  # renormalize in [0, 1]
            sigma_cur = (1 - at).sqrt() / at.sqrt()  # sigma_t

            x0_t = 2 * model(aux_x, sigma_cur / 2) - 1
            x0_t = torch.clip(x0_t, -1.0, 1.0)  # optional

            # 2. likelihood gradient approximation
            l2_loss = data_fidelity(x0_t, y, physics).sqrt().sum()

        norm_grad = torch.autograd.grad(outputs=l2_loss, inputs=xt)[0]
        norm_grad = norm_grad.detach()

        sigma_tilde = ((1 - at / at_next) * (1 - at_next) / (1 - at)).sqrt() * eta
        c2 = ((1 - at_next) - sigma_tilde**2).sqrt()

        # 3. noise step
        epsilon = torch.randn_like(xt)

        # 4. DDPM(IM) step
        xt_next = (
            (at_next.sqrt() - c2 * at.sqrt() / (1 - at).sqrt()) * x0_t
            + sigma_tilde * epsilon
            + c2 * xt / (1 - at).sqrt()
            - norm_grad
        )
        x0_preds.append(x0_t.to("cpu"))
        xs.append(xt_next.to("cpu"))

    recon = xs[-1]

    # plot the results
    x = recon / 2 + 0.5
    imgs = [y, x, x_true]
    plot(imgs, titles=["measurement", "model output", "groundtruth"])





.. image-sg:: /auto_examples/sampling/images/sphx_glr_demo_dps_004.png
   :alt: measurement, model output, groundtruth
   :srcset: /auto_examples/sampling/images/sphx_glr_demo_dps_004.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/200 [00:00<?, ?it/s]      0%|          | 1/200 [00:00<01:29,  2.23it/s]      1%|          | 2/200 [00:00<01:28,  2.24it/s]      2%|▏         | 3/200 [00:01<01:27,  2.25it/s]      2%|▏         | 4/200 [00:01<01:27,  2.25it/s]      2%|▎         | 5/200 [00:02<01:26,  2.26it/s]      3%|▎         | 6/200 [00:02<01:26,  2.24it/s]      4%|▎         | 7/200 [00:03<01:25,  2.25it/s]      4%|▍         | 8/200 [00:03<01:25,  2.24it/s]      4%|▍         | 9/200 [00:04<01:25,  2.24it/s]      5%|▌         | 10/200 [00:04<01:25,  2.23it/s]      6%|▌         | 11/200 [00:04<01:24,  2.24it/s]      6%|▌         | 12/200 [00:05<01:23,  2.24it/s]      6%|▋         | 13/200 [00:05<01:22,  2.25it/s]      7%|▋         | 14/200 [00:06<01:22,  2.25it/s]      8%|▊         | 15/200 [00:06<01:22,  2.25it/s]      8%|▊         | 16/200 [00:07<01:21,  2.25it/s]      8%|▊         | 17/200 [00:07<01:21,  2.25it/s]      9%|▉         | 18/200 [00:08<01:20,  2.25it/s]     10%|▉         | 19/200 [00:08<01:23,  2.16it/s]     10%|█         | 20/200 [00:08<01:22,  2.19it/s]     10%|█         | 21/200 [00:09<01:21,  2.21it/s]     11%|█         | 22/200 [00:09<01:20,  2.22it/s]     12%|█▏        | 23/200 [00:10<01:19,  2.24it/s]     12%|█▏        | 24/200 [00:10<01:18,  2.25it/s]     12%|█▎        | 25/200 [00:11<01:17,  2.25it/s]     13%|█▎        | 26/200 [00:11<01:17,  2.25it/s]     14%|█▎        | 27/200 [00:12<01:17,  2.24it/s]     14%|█▍        | 28/200 [00:12<01:16,  2.24it/s]     14%|█▍        | 29/200 [00:12<01:16,  2.25it/s]     15%|█▌        | 30/200 [00:13<01:15,  2.25it/s]     16%|█▌        | 31/200 [00:13<01:15,  2.25it/s]     16%|█▌        | 32/200 [00:14<01:14,  2.25it/s]     16%|█▋        | 33/200 [00:14<01:14,  2.25it/s]     17%|█▋        | 34/200 [00:15<01:13,  2.25it/s]     18%|█▊        | 35/200 [00:15<01:13,  2.25it/s]     18%|█▊        | 36/200 [00:16<01:12,  2.26it/s]     18%|█▊        | 37/200 [00:16<01:12,  2.26it/s]     19%|█▉        | 38/200 [00:16<01:11,  2.26it/s]     20%|█▉        | 39/200 [00:17<01:11,  2.26it/s]     20%|██        | 40/200 [00:17<01:10,  2.26it/s]     20%|██        | 41/200 [00:18<01:10,  2.26it/s]     21%|██        | 42/200 [00:18<01:09,  2.27it/s]     22%|██▏       | 43/200 [00:19<01:09,  2.27it/s]     22%|██▏       | 44/200 [00:19<01:09,  2.25it/s]     22%|██▎       | 45/200 [00:20<01:08,  2.25it/s]     23%|██▎       | 46/200 [00:20<01:08,  2.25it/s]     24%|██▎       | 47/200 [00:20<01:07,  2.26it/s]     24%|██▍       | 48/200 [00:21<01:07,  2.26it/s]     24%|██▍       | 49/200 [00:21<01:06,  2.26it/s]     25%|██▌       | 50/200 [00:22<01:06,  2.26it/s]     26%|██▌       | 51/200 [00:22<01:06,  2.25it/s]     26%|██▌       | 52/200 [00:23<01:05,  2.25it/s]     26%|██▋       | 53/200 [00:23<01:05,  2.25it/s]     27%|██▋       | 54/200 [00:24<01:04,  2.25it/s]     28%|██▊       | 55/200 [00:24<01:04,  2.26it/s]     28%|██▊       | 56/200 [00:24<01:03,  2.26it/s]     28%|██▊       | 57/200 [00:25<01:03,  2.27it/s]     29%|██▉       | 58/200 [00:25<01:02,  2.26it/s]     30%|██▉       | 59/200 [00:26<01:02,  2.26it/s]     30%|███       | 60/200 [00:26<01:01,  2.27it/s]     30%|███       | 61/200 [00:27<01:01,  2.26it/s]     31%|███       | 62/200 [00:27<01:00,  2.27it/s]     32%|███▏      | 63/200 [00:28<01:00,  2.26it/s]     32%|███▏      | 64/200 [00:28<01:00,  2.26it/s]     32%|███▎      | 65/200 [00:28<00:59,  2.26it/s]     33%|███▎      | 66/200 [00:29<00:59,  2.27it/s]     34%|███▎      | 67/200 [00:29<00:58,  2.27it/s]     34%|███▍      | 68/200 [00:30<00:58,  2.27it/s]     34%|███▍      | 69/200 [00:30<00:57,  2.27it/s]     35%|███▌      | 70/200 [00:31<00:57,  2.27it/s]     36%|███▌      | 71/200 [00:31<00:56,  2.27it/s]     36%|███▌      | 72/200 [00:31<00:56,  2.25it/s]     36%|███▋      | 73/200 [00:32<00:56,  2.24it/s]     37%|███▋      | 74/200 [00:32<00:56,  2.25it/s]     38%|███▊      | 75/200 [00:33<00:55,  2.26it/s]     38%|███▊      | 76/200 [00:33<00:54,  2.26it/s]     38%|███▊      | 77/200 [00:34<00:54,  2.26it/s]     39%|███▉      | 78/200 [00:34<00:53,  2.26it/s]     40%|███▉      | 79/200 [00:35<00:53,  2.25it/s]     40%|████      | 80/200 [00:35<00:53,  2.25it/s]     40%|████      | 81/200 [00:35<00:52,  2.26it/s]     41%|████      | 82/200 [00:36<00:52,  2.26it/s]     42%|████▏     | 83/200 [00:36<00:51,  2.26it/s]     42%|████▏     | 84/200 [00:37<00:51,  2.27it/s]     42%|████▎     | 85/200 [00:37<00:50,  2.27it/s]     43%|████▎     | 86/200 [00:38<00:50,  2.27it/s]     44%|████▎     | 87/200 [00:38<00:50,  2.23it/s]     44%|████▍     | 88/200 [00:39<00:50,  2.24it/s]     44%|████▍     | 89/200 [00:39<00:49,  2.24it/s]     45%|████▌     | 90/200 [00:39<00:48,  2.26it/s]     46%|████▌     | 91/200 [00:40<00:48,  2.26it/s]     46%|████▌     | 92/200 [00:40<00:47,  2.27it/s]     46%|████▋     | 93/200 [00:41<00:47,  2.26it/s]     47%|████▋     | 94/200 [00:41<00:46,  2.26it/s]     48%|████▊     | 95/200 [00:42<00:46,  2.26it/s]     48%|████▊     | 96/200 [00:42<00:45,  2.27it/s]     48%|████▊     | 97/200 [00:43<00:45,  2.27it/s]     49%|████▉     | 98/200 [00:43<00:45,  2.27it/s]     50%|████▉     | 99/200 [00:43<00:44,  2.27it/s]     50%|█████     | 100/200 [00:44<00:43,  2.27it/s]     50%|█████     | 101/200 [00:44<00:43,  2.27it/s]     51%|█████     | 102/200 [00:45<00:43,  2.27it/s]     52%|█████▏    | 103/200 [00:45<00:42,  2.27it/s]     52%|█████▏    | 104/200 [00:46<00:42,  2.27it/s]     52%|█████▎    | 105/200 [00:46<00:42,  2.26it/s]     53%|█████▎    | 106/200 [00:47<00:41,  2.27it/s]     54%|█████▎    | 107/200 [00:47<00:40,  2.27it/s]     54%|█████▍    | 108/200 [00:47<00:40,  2.27it/s]     55%|█████▍    | 109/200 [00:48<00:40,  2.26it/s]     55%|█████▌    | 110/200 [00:48<00:39,  2.26it/s]     56%|█████▌    | 111/200 [00:49<00:39,  2.26it/s]     56%|█████▌    | 112/200 [00:49<00:38,  2.26it/s]     56%|█████▋    | 113/200 [00:50<00:38,  2.26it/s]     57%|█████▋    | 114/200 [00:50<00:37,  2.27it/s]     57%|█████▊    | 115/200 [00:51<00:38,  2.23it/s]     58%|█████▊    | 116/200 [00:51<00:37,  2.24it/s]     58%|█████▊    | 117/200 [00:51<00:37,  2.24it/s]     59%|█████▉    | 118/200 [00:52<00:36,  2.25it/s]     60%|█████▉    | 119/200 [00:52<00:35,  2.25it/s]     60%|██████    | 120/200 [00:53<00:35,  2.25it/s]     60%|██████    | 121/200 [00:53<00:35,  2.25it/s]     61%|██████    | 122/200 [00:54<00:34,  2.26it/s]     62%|██████▏   | 123/200 [00:54<00:34,  2.25it/s]     62%|██████▏   | 124/200 [00:55<00:33,  2.26it/s]     62%|██████▎   | 125/200 [00:55<00:33,  2.26it/s]     63%|██████▎   | 126/200 [00:55<00:32,  2.26it/s]     64%|██████▎   | 127/200 [00:56<00:32,  2.26it/s]     64%|██████▍   | 128/200 [00:56<00:31,  2.26it/s]     64%|██████▍   | 129/200 [00:57<00:31,  2.26it/s]     65%|██████▌   | 130/200 [00:57<00:30,  2.26it/s]     66%|██████▌   | 131/200 [00:58<00:30,  2.26it/s]     66%|██████▌   | 132/200 [00:58<00:30,  2.26it/s]     66%|██████▋   | 133/200 [00:58<00:29,  2.26it/s]     67%|██████▋   | 134/200 [00:59<00:29,  2.27it/s]     68%|██████▊   | 135/200 [00:59<00:28,  2.26it/s]     68%|██████▊   | 136/200 [01:00<00:28,  2.26it/s]     68%|██████▊   | 137/200 [01:00<00:27,  2.27it/s]     69%|██████▉   | 138/200 [01:01<00:27,  2.27it/s]     70%|██████▉   | 139/200 [01:01<00:26,  2.26it/s]     70%|███████   | 140/200 [01:02<00:26,  2.27it/s]     70%|███████   | 141/200 [01:02<00:25,  2.27it/s]     71%|███████   | 142/200 [01:02<00:25,  2.24it/s]     72%|███████▏  | 143/200 [01:03<00:25,  2.25it/s]     72%|███████▏  | 144/200 [01:03<00:24,  2.25it/s]     72%|███████▎  | 145/200 [01:04<00:24,  2.26it/s]     73%|███████▎  | 146/200 [01:04<00:23,  2.27it/s]     74%|███████▎  | 147/200 [01:05<00:23,  2.27it/s]     74%|███████▍  | 148/200 [01:05<00:22,  2.27it/s]     74%|███████▍  | 149/200 [01:06<00:22,  2.26it/s]     75%|███████▌  | 150/200 [01:06<00:22,  2.26it/s]     76%|███████▌  | 151/200 [01:06<00:21,  2.27it/s]     76%|███████▌  | 152/200 [01:07<00:21,  2.28it/s]     76%|███████▋  | 153/200 [01:07<00:20,  2.27it/s]     77%|███████▋  | 154/200 [01:08<00:20,  2.27it/s]     78%|███████▊  | 155/200 [01:08<00:19,  2.27it/s]     78%|███████▊  | 156/200 [01:09<00:19,  2.27it/s]     78%|███████▊  | 157/200 [01:09<00:18,  2.27it/s]     79%|███████▉  | 158/200 [01:10<00:18,  2.27it/s]     80%|███████▉  | 159/200 [01:10<00:18,  2.27it/s]     80%|████████  | 160/200 [01:10<00:17,  2.27it/s]     80%|████████  | 161/200 [01:11<00:17,  2.27it/s]     81%|████████  | 162/200 [01:11<00:16,  2.27it/s]     82%|████████▏ | 163/200 [01:12<00:16,  2.27it/s]     82%|████████▏ | 164/200 [01:12<00:15,  2.27it/s]     82%|████████▎ | 165/200 [01:13<00:15,  2.27it/s]     83%|████████▎ | 166/200 [01:13<00:14,  2.27it/s]     84%|████████▎ | 167/200 [01:13<00:14,  2.27it/s]     84%|████████▍ | 168/200 [01:14<00:14,  2.27it/s]     84%|████████▍ | 169/200 [01:14<00:13,  2.27it/s]     85%|████████▌ | 170/200 [01:15<00:13,  2.27it/s]     86%|████████▌ | 171/200 [01:15<00:12,  2.24it/s]     86%|████████▌ | 172/200 [01:16<00:12,  2.24it/s]     86%|████████▋ | 173/200 [01:16<00:12,  2.25it/s]     87%|████████▋ | 174/200 [01:17<00:11,  2.25it/s]     88%|████████▊ | 175/200 [01:17<00:11,  2.26it/s]     88%|████████▊ | 176/200 [01:17<00:10,  2.26it/s]     88%|████████▊ | 177/200 [01:18<00:10,  2.26it/s]     89%|████████▉ | 178/200 [01:18<00:09,  2.26it/s]     90%|████████▉ | 179/200 [01:19<00:09,  2.26it/s]     90%|█████████ | 180/200 [01:19<00:08,  2.27it/s]     90%|█████████ | 181/200 [01:20<00:08,  2.27it/s]     91%|█████████ | 182/200 [01:20<00:07,  2.26it/s]     92%|█████████▏| 183/200 [01:21<00:07,  2.26it/s]     92%|█████████▏| 184/200 [01:21<00:07,  2.26it/s]     92%|█████████▎| 185/200 [01:21<00:06,  2.26it/s]     93%|█████████▎| 186/200 [01:22<00:06,  2.27it/s]     94%|█████████▎| 187/200 [01:22<00:05,  2.27it/s]     94%|█████████▍| 188/200 [01:23<00:05,  2.27it/s]     94%|█████████▍| 189/200 [01:23<00:04,  2.26it/s]     95%|█████████▌| 190/200 [01:24<00:04,  2.27it/s]     96%|█████████▌| 191/200 [01:24<00:03,  2.27it/s]     96%|█████████▌| 192/200 [01:25<00:03,  2.27it/s]     96%|█████████▋| 193/200 [01:25<00:03,  2.27it/s]     97%|█████████▋| 194/200 [01:25<00:02,  2.27it/s]     98%|█████████▊| 195/200 [01:26<00:02,  2.27it/s]     98%|█████████▊| 196/200 [01:26<00:01,  2.27it/s]     98%|█████████▊| 197/200 [01:27<00:01,  2.28it/s]     99%|█████████▉| 198/200 [01:27<00:00,  2.27it/s]    100%|█████████▉| 199/200 [01:28<00:00,  2.27it/s]    100%|██████████| 200/200 [01:28<00:00,  2.27it/s]    100%|██████████| 200/200 [01:28<00:00,  2.26it/s]




.. GENERATED FROM PYTHON SOURCE LINES 352-362

Using DPS in your inverse problem
---------------------------------
You can readily use this algorithm via the :class:`deepinv.sampling.DPS` class.

::

      y = physics(x)
      model = dinv.sampling.DPS(dinv.models.DiffUNet(), data_fidelity=dinv.optim.data_fidelity.L2())
      xhat = model(y, physics)



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 31.376 seconds)


.. _sphx_glr_download_auto_examples_sampling_demo_dps.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_dps.ipynb <demo_dps.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_dps.py <demo_dps.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: demo_dps.zip <demo_dps.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

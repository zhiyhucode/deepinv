
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/self-supervised-learning/demo_splitting_loss.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_self-supervised-learning_demo_splitting_loss.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_self-supervised-learning_demo_splitting_loss.py:


Self-supervised learning with measurement splitting
===================================================

We demonstrate self-supervised learning with measurement splitting, to
train a denoiser network on the MNIST dataset. The physics here is noisy
computed tomography, as is the case in
`Noise2Inverse <https://arxiv.org/abs/2001.11801>`__. Note this example
can also be easily applied to undersampled multicoil MRI as is the case
in `SSDU <https://pubmed.ncbi.nlm.nih.gov/32614100/>`__.

Measurement splitting constructs a ground-truth free loss
:math:`\frac{m}{m_2}\| y_2 - A_2 \inversef{y_1}{A_1}\|^2` by splitting
the measurement and the forward operator using a randomly generated
mask.

See :class:`deepinv.loss.SplittingLoss` for full details.

.. GENERATED FROM PYTHON SOURCE LINES 20-39

.. code-block:: Python


    from pathlib import Path

    import torch
    from torch.utils.data import DataLoader
    from torchvision import transforms, datasets

    import deepinv as dinv
    from deepinv.utils.demo import get_data_home
    from deepinv.models.utils import get_weights_url

    torch.manual_seed(0)
    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"

    BASE_DIR = Path(".")
    DATA_DIR = BASE_DIR / "measurements"
    ORIGINAL_DATA_HOME = get_data_home()









.. GENERATED FROM PYTHON SOURCE LINES 40-63

Define loss
~~~~~~~~~~~

Our implementation has multiple optional parameters that control how the
splitting is to be achieved. For example, you can:

-  Use ``split_ratio`` to set the ratio of pixels used in the forward
   pass vs the loss;
-  Define custom masking methods using a ``mask_generator`` such as
   :class:`deepinv.physics.generator.BernoulliSplittingMaskGenerator`
   or :class:`deepinv.physics.generator.GaussianSplittingMaskGenerator`;
-  Use ``eval_n_samples`` to set how many realisations of the random
   mask is used at evaluation time;
-  Optionally disable measurement splitting at evaluation time using
   ``eval_split_input`` (as is the case in
   `SSDU <https://pubmed.ncbi.nlm.nih.gov/32614100/>`__).
-  Average over both input and output masks at evaluation time using
   ``eval_split_output``. See :class:`deepinv.loss.SplittingLoss` for
   details.

Note that after the model has been defined, the loss must also "adapt"
the model.


.. GENERATED FROM PYTHON SOURCE LINES 63-67

.. code-block:: Python


    loss = dinv.loss.SplittingLoss(split_ratio=0.6, eval_split_input=True, eval_n_samples=5)









.. GENERATED FROM PYTHON SOURCE LINES 68-80

Prepare data
~~~~~~~~~~~~

We use the ``torchvision`` MNIST dataset, and use noisy tomography
physics (with number of angles equal to the image size) for the forward
operator.

.. note::

     We use a subset of the whole training set to reduce the computational load of the example.
     We recommend to use the whole set by setting ``train_datapoints=test_datapoints=None`` to get the best results.


.. GENERATED FROM PYTHON SOURCE LINES 80-114

.. code-block:: Python


    transform = transforms.Compose([transforms.ToTensor()])

    train_dataset = datasets.MNIST(
        root=ORIGINAL_DATA_HOME, train=True, transform=transform, download=True
    )
    test_dataset = datasets.MNIST(
        root=ORIGINAL_DATA_HOME, train=False, transform=transform, download=True
    )

    physics = dinv.physics.Tomography(
        angles=28,
        img_width=28,
        noise_model=dinv.physics.noise.GaussianNoise(0.1),
        device=device,
    )

    deepinv_datasets_path = dinv.datasets.generate_dataset(
        train_dataset=train_dataset,
        test_dataset=test_dataset,
        physics=physics,
        device=device,
        save_dir=DATA_DIR,
        train_datapoints=100,
        test_datapoints=10,
    )

    train_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)
    test_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)

    train_dataloader = DataLoader(train_dataset, shuffle=True)
    test_dataloader = DataLoader(test_dataset, shuffle=False)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0.00/9.91M [00:00<?, ?B/s]      1%|          | 98.3k/9.91M [00:00<00:13, 703kB/s]      4%|▍         | 393k/9.91M [00:00<00:06, 1.53MB/s]     15%|█▌        | 1.51M/9.91M [00:00<00:01, 4.45MB/s]     60%|██████    | 5.96M/9.91M [00:00<00:00, 15.3MB/s]    100%|██████████| 9.91M/9.91M [00:00<00:00, 17.3MB/s]
      0%|          | 0.00/28.9k [00:00<?, ?B/s]    100%|██████████| 28.9k/28.9k [00:00<00:00, 400kB/s]
      0%|          | 0.00/1.65M [00:00<?, ?B/s]      4%|▍         | 65.5k/1.65M [00:00<00:03, 467kB/s]     24%|██▍       | 393k/1.65M [00:00<00:00, 1.56MB/s]     99%|█████████▉| 1.64M/1.65M [00:00<00:00, 4.88MB/s]    100%|██████████| 1.65M/1.65M [00:00<00:00, 3.90MB/s]
      0%|          | 0.00/4.54k [00:00<?, ?B/s]    100%|██████████| 4.54k/4.54k [00:00<00:00, 24.8MB/s]
    Dataset has been saved at measurements/dinv_dataset0.h5




.. GENERATED FROM PYTHON SOURCE LINES 115-129

Define model
~~~~~~~~~~~~

We use a simple U-Net architecture with 2 scales as the denoiser
network.

To reduce training time, we use a pretrained model. Here we demonstrate
training with 100 images for 1 epoch, after having loaded a pretrained
model trained that was with 1000 images for 20 epochs.

.. note::

     When using the splitting loss, the model must be "adapted" by the loss, as its forward pass takes only a subset of the pixels, not the full image.


.. GENERATED FROM PYTHON SOURCE LINES 129-148

.. code-block:: Python


    model = dinv.models.ArtifactRemoval(
        dinv.models.UNet(in_channels=1, out_channels=1, scales=2).to(device), pinv=True
    )
    model = loss.adapt_model(model)

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-8)

    # Load pretrained model
    file_name = "demo_measplit_mnist_tomography.pth"
    url = get_weights_url(model_name="measplit", file_name=file_name)
    ckpt = torch.hub.load_state_dict_from_url(
        url, map_location=lambda storage, loc: storage, file_name=file_name
    )

    model.load_state_dict(ckpt["state_dict"])
    optimizer.load_state_dict(ckpt["optimizer"])






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://huggingface.co/deepinv/measplit/resolve/main/demo_measplit_mnist_tomography.pth?download=true" to /home/runner/.cache/torch/hub/checkpoints/demo_measplit_mnist_tomography.pth
      0%|          | 0.00/5.13M [00:00<?, ?B/s]    100%|██████████| 5.13M/5.13M [00:00<00:00, 273MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 149-152

Train and test network
----------------------


.. GENERATED FROM PYTHON SOURCE LINES 152-171

.. code-block:: Python


    trainer = dinv.Trainer(
        model=model,
        physics=physics,
        epochs=1,
        losses=loss,
        optimizer=optimizer,
        device=device,
        train_dataloader=train_dataloader,
        plot_images=False,
        save_path=None,
        verbose=True,
        show_progress_bar=False,
        no_learning_method="A_dagger",  # use pseudo-inverse as no-learning baseline
    )

    model = trainer.train()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The model has 444737 trainable parameters
    /home/runner/work/deepinv/deepinv/deepinv/loss/measplit.py:273: UserWarning: Mask generator not defined. Using new Bernoulli mask generator.
      warn("Mask generator not defined. Using new Bernoulli mask generator.")
    /home/runner/work/deepinv/deepinv/deepinv/physics/forward.py:785: UserWarning: At least one input physics is a DecomposablePhysics, but resulting physics will not be decomposable. `A_dagger` and `prox_l2` will fall back to approximate methods, which may impact performance.
      warnings.warn(
    Train epoch 0: TotalLoss=0.032, PSNR=28.999




.. GENERATED FROM PYTHON SOURCE LINES 172-176

Test and visualise the model outputs using a small test set. We set the
output to average over 5 iterations of random mask realisations. The
trained model improves on the no-learning reconstruction by ~7dB.


.. GENERATED FROM PYTHON SOURCE LINES 176-181

.. code-block:: Python


    trainer.plot_images = True
    trainer.test(test_dataloader)





.. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_001.png
   :alt: Ground truth, No learning, Reconstruction
   :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Eval epoch 0: PSNR=31.157, PSNR no learning=24.549
    Test results:
    PSNR no learning: 24.549 +- 1.052
    PSNR: 31.157 +- 2.742

    {'PSNR no learning': np.float64(24.548789978027344), 'PSNR no learning_std': np.float64(1.0523070216572739), 'PSNR': np.float64(31.157159423828126), 'PSNR_std': np.float64(2.741690328412059)}



.. GENERATED FROM PYTHON SOURCE LINES 182-186

Demonstrate the effect of not averaging over multiple realisations of
the splitting mask at evaluation time, by setting ``eval_n_samples=1``.
We have a worse performance:


.. GENERATED FROM PYTHON SOURCE LINES 186-191

.. code-block:: Python


    model.eval_n_samples = 1
    trainer.test(test_dataloader)





.. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_002.png
   :alt: Ground truth, No learning, Reconstruction
   :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Eval epoch 0: PSNR=29.164, PSNR no learning=24.549
    Test results:
    PSNR no learning: 24.549 +- 1.052
    PSNR: 29.164 +- 2.453

    {'PSNR no learning': np.float64(24.548789978027344), 'PSNR no learning_std': np.float64(1.0523070216572739), 'PSNR': np.float64(29.163711547851562), 'PSNR_std': np.float64(2.45347311299908)}



.. GENERATED FROM PYTHON SOURCE LINES 192-197

Furthermore, we can disable measurement splitting at evaluation
altogether by setting ``eval_split_input`` to False (this is done in
`SSDU <https://pubmed.ncbi.nlm.nih.gov/32614100/>`__). This generally is
worse than MC averaging:


.. GENERATED FROM PYTHON SOURCE LINES 197-200

.. code-block:: Python


    model.eval_split_input = False
    trainer.test(test_dataloader)



.. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_003.png
   :alt: Ground truth, No learning, Reconstruction
   :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Eval epoch 0: PSNR=30.966, PSNR no learning=24.549
    Test results:
    PSNR no learning: 24.549 +- 1.052
    PSNR: 30.966 +- 2.493

    {'PSNR no learning': np.float64(24.548789978027344), 'PSNR no learning_std': np.float64(1.0523070216572739), 'PSNR': np.float64(30.966433715820312), 'PSNR_std': np.float64(2.4932139371115007)}




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 12.751 seconds)


.. _sphx_glr_download_auto_examples_self-supervised-learning_demo_splitting_loss.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_splitting_loss.ipynb <demo_splitting_loss.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_splitting_loss.py <demo_splitting_loss.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: demo_splitting_loss.zip <demo_splitting_loss.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
